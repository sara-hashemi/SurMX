# -*- coding: utf-8 -*-
"""MIL_MM_OS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T0p1oa553dcFLT6FbdT4Qrzf5Nlhcbse
"""

!pip install nibabel SimpleITK monai scikit-image pandas scikit-learn pyradiomics matplotlib seaborn
!pip install lifelines scikit-survival
!pip install xgboost==1.6.2

# EVENT ----> DEATH

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
import warnings
import copy

warnings.filterwarnings("ignore")

# =====================================================
#   CONFIGURATION (ABLATION STUDY)
# =====================================================
TARGET_EVENT = "death"

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")
print(f"Running ABLATION (Single Head) for Target: {TARGET_EVENT.upper()}")

EMB_DIM = 16
NUM_NUMERIC = 4
BATCH_SIZE = 16
LR = 2e-4
EPOCHS = 20

# =====================================================
#   DATA PREPARATION (Exact same as before)
# =====================================================
df = pd.read_csv("features_merged_clinical_all.csv")
df["patient_id"] = df["patient_id"].astype(str)

tumor_cols  = [c for c in df.columns if c.startswith("deep_tumor_")]
global_cols = [c for c in df.columns if c.startswith("deep_global_")]

df[tumor_cols]  = df[tumor_cols].astype(np.float32)
df[global_cols] = df[global_cols].astype(np.float32)

clinical_numeric = ["age", "weight", "patient_size", "oncotype_score"]

clinical_categorical = [
    "ethnicity", "tumor_subtype", "menopause",
    "nac_agent", "endocrine_therapy",
    "anti_her2_neu_therapy", "pcr",
    "er", "pr", "her2", "hr",
    "nottingham_grade", "mammaprint", "bmi_group"
]

df[clinical_numeric] = df[clinical_numeric].apply(pd.to_numeric, errors="coerce")
df[clinical_numeric] = df[clinical_numeric].fillna(df[clinical_numeric].mean())

bad = ["nan", "none", "null", "", " ", "na", "n/a", "nan "]
for col in clinical_categorical:
    df[col] = df[col].astype(str).str.strip().str.lower().replace(bad, "unk")

# --- Categorical Padding ---
cat_to_idx = {}
for col in clinical_categorical:
    vals = sorted(df[col].unique().tolist())
    if "unk" not in vals:
        vals.insert(0, "unk")
    if len(vals) == 1:
        vals.append("_pad")

    cat_to_idx[col] = {v: i for i, v in enumerate(vals)}
    df[col] = df[col].apply(lambda x: x if x in cat_to_idx[col] else "unk")

# =============================================================
#       MANUAL METRIC
# =============================================================
def concordance_index(times, risks, events):
    """Calculates C-index without requiring external libraries."""
    n = len(times)
    count = 0.0
    total_pairs = 0.0

    for i in range(n):
        for j in range(i + 1, n):
            if times[i] < times[j]:
                shorter, longer = i, j
            elif times[i] > times[j]:
                shorter, longer = j, i
            else:
                continue

            if events[shorter] == 1:
                total_pairs += 1
                if risks[shorter] > risks[longer]:
                    count += 1.0
                elif risks[shorter] == risks[longer]:
                    count += 0.5

    return count / total_pairs if total_pairs > 0 else 0.5

# =============================================================
#       BUILD TENSORS
# =============================================================
bags = {}
globals_dict = {}
clinical_dict = {}
targets = {}

print("\nBuilding per-patient tensors...")

for pid, g in df.groupby("patient_id"):
    bags[pid] = torch.from_numpy(np.ascontiguousarray(g[tumor_cols].values.astype(np.float32)))
    globals_dict[pid] = torch.from_numpy(np.ascontiguousarray(g[global_cols].iloc[0].values.astype(np.float32)))

    cat_idx = [cat_to_idx[c][g[c].iloc[0]] for c in clinical_categorical]
    cat_vec = torch.tensor(cat_idx, dtype=torch.long)
    num_vec = torch.tensor(g[clinical_numeric].iloc[0].values.astype(np.float32), dtype=torch.float32)
    clinical_dict[pid] = {"categorical": cat_vec, "numeric": num_vec}

    if TARGET_EVENT == "death":
        t = float(g["duration_death"].iloc[0])
        e = int(g["event_death"].iloc[0])
    elif TARGET_EVENT == "recurrence":
        t = float(g["duration_recurrence"].iloc[0])
        e = int(g["event_recurrence"].iloc[0])

    targets[pid] = {"time": t, "event": e}

pat_ids = list(bags.keys())
print(f"âœ” All patient tensors built. Target: {TARGET_EVENT}")

# =============================================================
#       MODEL DEFINITIONS (MODIFIED FOR ABLATION)
# =============================================================
class ClinicalEncoder(nn.Module):
    def __init__(self, cat_dims):
        super().__init__()
        self.emb = nn.ModuleList([nn.Embedding(n, EMB_DIM) for n in cat_dims])
        self.num_norm = nn.LayerNorm(NUM_NUMERIC)
        self.fc = nn.Linear(len(cat_dims)*EMB_DIM + NUM_NUMERIC, 128)

    def forward(self, cat_vec, num_vec):
        emb_list = [self.emb[i](cat_vec[i]) for i in range(len(self.emb))]
        emb_cat = torch.cat(emb_list, dim=0)
        num_norm = self.num_norm(num_vec)
        x = torch.cat([emb_cat, num_norm], dim=0)
        return torch.relu(self.fc(x))

class ResMLP(nn.Module):
    def __init__(self, dim=256):
        super().__init__()
        self.fc1 = nn.Linear(dim, dim)
        self.fc2 = nn.Linear(dim, dim)
        self.norm = nn.LayerNorm(dim)
        self.act = nn.GELU()

    def forward(self, x):
        r = x
        x = self.norm(x)
        x = self.act(self.fc1(x))
        x = self.fc2(x)
        return x + r

# --- ABLATION CHANGE: REPLACED MULTI-HEAD WITH SINGLE SIMPLE ATTENTION ---
class SimpleAttentionMIL(nn.Module):
    def __init__(self, dim=256):
        super().__init__()
        # Just one simple linear layer to calculate attention weights
        self.attn_layer = nn.Linear(dim, 1)

    def forward(self, x):
        # x shape: [bag_size, dim]
        # Calculate attention scores
        scores = self.attn_layer(x)
        w = torch.softmax(scores, dim=0)
        # Weighted sum of instances
        return (w * x).sum(dim=0)

class SingleTaskSurvModel(nn.Module):
    def __init__(self, cat_dims):
        super().__init__()
        self.clin = ClinicalEncoder(cat_dims)
        self.enc = ResMLP()

        # --- ABLATION: Using Simple Attention here ---
        self.mil = SimpleAttentionMIL(dim=256)
        # ---------------------------------------------

        self.glb = nn.Sequential(nn.Linear(256, 256), nn.ReLU())

        self.fuse = nn.Sequential(
            nn.Linear(256+256+128, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 128),
            nn.ReLU()
        )
        self.risk_head = nn.Linear(128, 1)

    def forward(self, tumor, global_vec, cat_vec, num_vec):
        clin_vec = self.clin(cat_vec, num_vec)
        enc = self.enc(tumor)
        z = self.mil(enc) # Single head attention aggregation
        g = self.glb(global_vec)

        h = self.fuse(torch.cat([z, g, clin_vec], dim=0))
        return self.risk_head(h)

# =============================================================
#       LOSS & TRAIN (Same)
# =============================================================
def cox_loss(risk, time, event):
    risk = risk.reshape(-1)
    time = torch.tensor(time, dtype=torch.float32, device=device)
    event = torch.tensor(event, dtype=torch.float32, device=device)

    idx = torch.argsort(time, descending=True)
    risk = risk[idx]
    event = event[idx]

    log_cumsum = torch.logcumsumexp(risk, dim=0)
    loss_val = (-(risk - log_cumsum) * event).sum() / (event.sum() + 1e-8)
    return loss_val

def evaluate(model, test_ids):
    model.eval()
    risks, times, events = [], [], []

    with torch.no_grad():
        for pid in test_ids:
            tumor = bags[pid].to(device)
            glb   = globals_dict[pid].to(device)
            cat   = clinical_dict[pid]["categorical"].to(device)
            num   = clinical_dict[pid]["numeric"].to(device)

            pred = model(tumor, glb, cat, num)

            risks.append(float(pred))
            times.append(targets[pid]["time"])
            events.append(targets[pid]["event"])

    return concordance_index(times, risks, events)

def train_one_fold(train_ids, test_ids):
    cat_dims = [len(cat_to_idx[c]) for c in clinical_categorical]
    model = SingleTaskSurvModel(cat_dims).to(device)
    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)

    best_c = 0.0
    best_model_wts = copy.deepcopy(model.state_dict())

    print(f"\nStarting training ({len(train_ids)} train, {len(test_ids)} test)")

    for ep in range(EPOCHS):
        model.train()
        np.random.shuffle(train_ids)
        batch_losses = []

        for i in range(0, len(train_ids), BATCH_SIZE):
            batch_pids = train_ids[i:i+BATCH_SIZE]
            opt.zero_grad()

            batch_risks, batch_times, batch_events = [], [], []

            for pid in batch_pids:
                tumor = bags[pid].to(device)
                glb   = globals_dict[pid].to(device)
                cat   = clinical_dict[pid]["categorical"].to(device)
                num   = clinical_dict[pid]["numeric"].to(device)

                risk = model(tumor, glb, cat, num)

                batch_risks.append(risk)
                batch_times.append(targets[pid]["time"])
                batch_events.append(targets[pid]["event"])

            if len(batch_events) < 2: continue
            if sum(batch_events) < 1: continue

            risks_t = torch.stack(batch_risks)
            loss = cox_loss(risks_t, batch_times, batch_events)

            loss.backward()
            opt.step()
            batch_losses.append(loss.item())

        val_c = evaluate(model, test_ids)
        if val_c > best_c:
            best_c = val_c
            best_model_wts = copy.deepcopy(model.state_dict())

        print(f"Ep {ep+1:02d} | Loss: {np.mean(batch_losses):.4f} | Val C-Index: {val_c:.4f}")

    print(f"Best Val C-Index: {best_c:.4f}")
    return best_model_wts, best_c

# =============================================================
#       STRATIFIED SPLIT & EXECUTION
# =============================================================

event_labels = [targets[pid]["event"] for pid in pat_ids]

train_ids, test_ids = train_test_split(
    pat_ids,
    test_size=0.20,
    random_state=42,
    stratify=event_labels
)

best_wts, final_score = train_one_fold(train_ids, test_ids)

# Saved with ABLATION tag
torch.save(best_wts, f"miccai_model_ABLATION_{TARGET_EVENT}.pth")
print(f"\nSaved best {TARGET_EVENT} ABLATION model with C-Index: {final_score:.4f}")