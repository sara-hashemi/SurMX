# -*- coding: utf-8 -*-
"""SurvMX.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cygRWrusbqiBagZIaN2rA5v-XMj5Yyto
"""

import os
import copy
import random
import warnings
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import StratifiedKFold, train_test_split
from lifelines import KaplanMeierFitter
from lifelines.statistics import logrank_test
import matplotlib.pyplot as plt

warnings.filterwarnings("ignore")

# ---------------------------------------------------------
# 1. REPRODUCIBILITY & GLOBAL CONFIG
# ---------------------------------------------------------
def seed_everything(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

# Configuration matches your updated experimental setup
CONFIG = {
    'target': 'recurrence', # or 'death'
    'heads': 2,             # 2 for recurrence, 1 for death
    'batch_size': 1,        # Batch size 1 for variable-sized MIL bags
    'lr': 2e-4,
    'weight_decay': 1e-4,
    'epochs': 20,
    'n_splits': 5,
    'seed': 42,
    'device': torch.device("cuda" if torch.cuda.is_available() else "cpu")
}

seed_everything(CONFIG['seed'])

# ---------------------------------------------------------
# 2. DATASET REPRESENTATION
# ---------------------------------------------------------
class SurvBagDataset(Dataset):
    """Encapsulates the 'Bag' structure for MIL survival analysis."""
    def __init__(self, pids, bags, globals_dict, clinical_dict, targets):
        self.pids = pids
        self.bags = bags
        self.globals = globals_dict
        self.clinical = clinical_dict
        self.targets = targets

    def __len__(self):
        return len(self.pids)

    def __getitem__(self, idx):
        pid = self.pids[idx]
        return {
            'pid': pid,
            'tumor': self.bags[pid],            # (K, 256)
            'global': self.globals[pid],        # (256,)
            'cat': self.clinical[pid]['categorical'],
            'num': self.clinical[pid]['numeric'],
            'time': torch.tensor(self.targets[pid]['time'], dtype=torch.float32),
            'event': torch.tensor(self.targets[pid]['event'], dtype=torch.float32)
        }

# ---------------------------------------------------------
# 3. ARCHITECTURAL BLOCKS
# ---------------------------------------------------------
class ResMLP(nn.Module):
    def __init__(self, dim=256):
        super().__init__()
        self.fc1 = nn.Linear(dim, dim)
        self.fc2 = nn.Linear(dim, dim)
        self.norm = nn.LayerNorm(dim)
        self.act = nn.GELU()

    def forward(self, x):
        return self.fc2(self.act(self.fc1(self.norm(x)))) + x

class MultiHeadAttnMIL(nn.Module):
    def __init__(self, dim=256, heads=1):
        super().__init__()
        self.heads = nn.ModuleList([nn.Linear(dim, 1) for _ in range(heads)])

    def forward(self, x):
        outs = []
        for h in self.heads:
            w = torch.softmax(h(x), dim=0)
            outs.append((w * x).sum(dim=0))
        return torch.stack(outs).mean(dim=0)

class SurvMxNet(nn.Module):
    def __init__(self, cat_dims, num_numeric, heads=1, dropout=0.2):
        super().__init__()
        self.clin_enc = nn.ModuleList([nn.Embedding(n, 16) for n in cat_dims])
        self.num_norm = nn.LayerNorm(num_numeric)
        self.clin_fc = nn.Linear(len(cat_dims)*16 + num_numeric, 128)
        self.tumor_res = ResMLP(dim=256)
        self.mil_pool = MultiHeadAttnMIL(dim=256, heads=heads)
        self.global_proj = nn.Sequential(nn.Linear(256, 256), nn.ReLU())
        self.fusion = nn.Sequential(
            nn.Linear(256 + 256 + 128, 256), nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(256, 128), nn.ReLU()
        )
        self.risk_classifier = nn.Linear(128, 1)

    def forward(self, tumor, global_vec, cat_vec, num_vec):
        embs = [self.clin_enc[i](cat_vec[:, i]) for i in range(len(self.clin_enc))]
        c = torch.relu(self.clin_fc(torch.cat(embs + [self.num_norm(num_vec)], dim=1)))
        z = self.mil_pool(self.tumor_res(tumor.squeeze(0)))
        g = self.global_proj(global_vec)
        feat = torch.cat([z.unsqueeze(0), g, c], dim=1)
        return self.risk_classifier(self.fusion(feat))

# ---------------------------------------------------------
# 4. LOSS & METRICS
# ---------------------------------------------------------
def cox_npll_loss(risk, time, event):
    risk = risk.view(-1)
    idx = torch.argsort(time, descending=True)
    risk, event = risk[idx], event[idx]
    log_cumsum = torch.logcumsumexp(risk, dim=0)
    return (-(risk - log_cumsum) * event).sum() / (event.sum() + 1e-8)

def concordance_index_manual(times, risks, events):
    n = len(times)
    count, total_pairs = 0.0, 0.0
    for i in range(n):
        for j in range(i + 1, n):
            if times[i] < times[j]: shorter, longer = i, j
            elif times[i] > times[j]: shorter, longer = j, i
            else: continue
            if events[shorter] == 1:
                total_pairs += 1
                if risks[shorter] > risks[longer]: count += 1.0
                elif risks[shorter] == risks[longer]: count += 0.5
    return count / total_pairs if total_pairs > 0 else 0.5

# ---------------------------------------------------------
# 5. EXPERIMENT ENGINE
# ---------------------------------------------------------
def evaluate_model(model, loader, device):
    model.eval()
    risks, times, events = [], [], []
    with torch.no_grad():
        for batch in loader:
            pred = model(batch['tumor'].to(device), batch['global'].to(device),
                         batch['cat'].to(device), batch['num'].to(device))
            risks.append(pred.item())
            times.append(batch['time'].item())
            events.append(batch['event'].item())
    c_index = concordance_index_manual(times, risks, events)
    return c_index, np.array(risks), np.array(times), np.array(events)

def train_fold(train_loader, val_loader, cat_dims, config):
    model = SurvMxNet(cat_dims, 4, heads=config['heads']).to(config['device'])
    optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])

    best_c, best_wts = -1.0, None
    for epoch in range(config['epochs']):
        model.train()
        for batch in train_loader:
            optimizer.zero_grad()
            pred = model(batch['tumor'].to(config['device']), batch['global'].to(config['device']),
                         batch['cat'].to(config['device']), batch['num'].to(config['device']))
            loss = cox_npll_loss(pred, batch['time'].to(config['device']), batch['event'].to(config['device']))
            loss.backward()
            optimizer.step()

        val_c, _, _, _ = evaluate_model(model, val_loader, config['device'])
        if val_c > best_c:
            best_c = val_c
            best_wts = copy.deepcopy(model.state_dict())

    return best_wts, best_c

# ---------------------------------------------------------
# 6. PLOTTING (KM CURVE)
# ---------------------------------------------------------
def plot_survival(times, risks, events, target_name, heads):
    median_risk = np.median(risks)
    high_risk = risks >= median_risk

    lr_res = logrank_test(times[high_risk], times[~high_risk], events[high_risk], events[~high_risk])

    plt.figure(figsize=(10, 7))
    kmf = KaplanMeierFitter()
    kmf.fit(times[high_risk], events[high_risk], label=f'High Risk (n={sum(high_risk)})')
    ax = kmf.plot_survival_function(color='red')
    kmf.fit(times[~high_risk], events[~high_risk], label=f'Low Risk (n={sum(~high_risk)})')
    kmf.plot_survival_function(ax=ax, color='blue')

    plt.title(f'Final Test Set: {target_name.upper()} (M={heads})\nLog-rank p: {lr_res.p_value:.2e}')
    plt.xlabel('Days'); plt.ylabel('Survival Probability')
    plt.savefig(f"km_{target_name}_{heads}heads.png", dpi=300)
    plt.show()

# ---------------------------------------------------------
# 7. MAIN PIPELINE
# ---------------------------------------------------------
# Note: This assumes 'bags', 'globals_dict', 'clinical_dict', 'targets',
# 'pat_ids', and 'event_labels' are pre-loaded from your previous blocks.

# 1. Global Split
train_val_ids, test_ids, _, _ = train_test_split(
    pat_ids, event_labels, test_size=0.20, random_state=CONFIG['seed'], stratify=event_labels
)

# 2. Cross Validation
skf = StratifiedKFold(n_splits=CONFIG['n_splits'], shuffle=True, random_state=CONFIG['seed'])
fold_scores = []
best_global_wts = None
max_val_c = -1.0

for fold, (t_idx, v_idx) in enumerate(skf.split(train_val_ids, event_labels[np.isin(pat_ids, train_val_ids)])):
    t_ds = SurvBagDataset(train_val_ids[t_idx], bags, globals_dict, clinical_dict, targets)
    v_ds = SurvBagDataset(train_val_ids[v_idx], bags, globals_dict, clinical_dict, targets)

    t_ldr = DataLoader(t_ds, batch_size=CONFIG['batch_size'], shuffle=True)
    v_ldr = DataLoader(v_ds, batch_size=CONFIG['batch_size'], shuffle=False)

    wts, val_c = train_fold(t_ldr, v_ldr, cat_dims, CONFIG)
    fold_scores.append(val_c)
    print(f"Fold {fold+1} Validation C-index: {val_c:.4f}")

    if val_c > max_val_c:
        max_val_c = val_c
        best_global_wts = wts

# 3. Final Test Evaluation
test_ds = SurvBagDataset(test_ids, bags, globals_dict, clinical_dict, targets)
test_ldr = DataLoader(test_ds, batch_size=CONFIG['batch_size'], shuffle=False)

final_model = SurvMxNet(cat_dims, 4, heads=CONFIG['heads']).to(CONFIG['device'])
final_model.load_state_dict(best_global_wts)
test_c, test_r, test_t, test_e = evaluate_model(final_model, test_ldr, CONFIG['device'])

print(f"\nCV Mean C-index: {np.mean(fold_scores):.4f} (+/- {np.std(fold_scores):.4f})")
print(f"Final Test C-index: {test_c:.4f}")

plot_survival(test_t, test_r, test_e, CONFIG['target'], CONFIG['heads'])